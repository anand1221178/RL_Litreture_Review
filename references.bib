@article{liu2023saving,
	title={Saving the limping: Fault-tolerant quadruped locomotion via reinforcement learning},
	author={Liu, Dikai and Zhang, Tianwei and Yin, Jianxiong and See, Simon},
	journal={arXiv preprint arXiv:2210.00474},
	year={2022}
}

@article{bongard2006resilient,
  title={Resilient machines through continuous self-modeling},
  author={Bongard, Josh and Zykov, Victor and Lipson, Hod},
  journal={Science},
  volume={314},
  number={5802},
  pages={1118--1121},
  year={2006},
  publisher={American Association for the Advancement of Science}
}
@article{pham2024adaptive,
  title={Adaptive Compensation for Robotic Joint Failures Using Partially Observable Reinforcement Learning},
  author={Pham, Tan-Hanh and Aikins, Godwyll and Truong, Tri and Nguyen, Kim-Doang},
  journal={Algorithms},
  volume={17},
  number={10},
  pages={436},
  year={2024},
  publisher={MDPI}
}

@article{blanke1997,
  title={Fault-tolerant control systemsâ€”a holistic view},
  author={Blanke, Mogens and Izadi-Zamanabadi, Roozbeh and B{\o}gh, S{\o}ren A and Lunau, Charlotte P},
  journal={Control Engineering Practice},
  volume={5},
  number={5},
  pages={693--702},
  year={1997},
  publisher={Elsevier}
}

@article{ahmed2020fault,
  title={Fault-tolerant control of degrading systems with on-policy reinforcement learning},
  author={Ahmed, Ibrahim and Qui{\~n}ones-Grueiro, Marcos and Biswas, Gautam},
  journal={IFAC-PapersOnLine},
  volume={53},
  number={2},
  pages={13733--13738},
  year={2020},
  publisher={Elsevier}
}

@article{rajeswaran2016epopt,
  title={Epopt: Learning robust neural network policies using model ensembles},
  author={Rajeswaran, Aravind and Ghotra, Sarvjeet and Ravindran, Balaraman and Levine, Sergey},
  journal={arXiv preprint arXiv:1610.01283},
  year={2016}
}

@inproceedings{pinto2017robust,
  title={Robust adversarial reinforcement learning},
  author={Pinto, Lerrel and Davidson, James and Sukthankar, Rahul and Gupta, Abhinav},
  booktitle={International conference on machine learning},
  pages={2817--2826},
  year={2017},
  organization={PMLR}
}

@inproceedings{tessler2019action,
  title={Action robust reinforcement learning and applications in continuous control},
  author={Tessler, Chen and Efroni, Yonathan and Mannor, Shie},
  booktitle={International Conference on Machine Learning},
  pages={6215--6224},
  year={2019},
  organization={PMLR}
}

@article{cully2015robots,
  title={Robots that can adapt like animals},
  author={Cully, Antoine and Clune, Jeff and Tarapore, Danesh and Mouret, Jean-Baptiste},
  journal={Nature},
  volume={521},
  number={7553},
  pages={503--507},
  year={2015},
  publisher={Nature Publishing Group UK London}
}

@inproceedings{shen2020deep,
  title={Deep reinforcement learning with robust and smooth policy},
  author={Shen, Qianli and Li, Yan and Jiang, Haoming and Wang, Zhaoran and Zhao, Tuo},
  booktitle={International Conference on Machine Learning},
  pages={8707--8718},
  year={2020},
  organization={PMLR}
}

@article{chatzilygeroudis2018reset,
  title={Reset-free trial-and-error learning for robot damage recovery},
  author={Chatzilygeroudis, Konstantinos and Vassiliades, Vassilis and Mouret, Jean-Baptiste},
  journal={Robotics and Autonomous Systems},
  volume={100},
  pages={236--250},
  year={2018},
  publisher={Elsevier}
}

@article{sutton2018,
  title={Reinforcement learning: an introduction},
  author={Andrew, Barto and Richard S, Sutton},
  year={2018},
  publisher={The MIT Press}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{levine2018learning,
  title={Learning hand-eye coordination for robotic grasping with deep learning and large-scale data collection},
  author={Levine, Sergey and Pastor, Peter and Krizhevsky, Alex and Ibarz, Julian and Quillen, Deirdre},
  journal={The International journal of robotics research},
  volume={37},
  number={4-5},
  pages={421--436},
  year={2018},
  publisher={SAGE Publications Sage UK: London, England}
}
@article{silver2017mastering,
  title={Mastering the game of go without human knowledge},
  author={Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and others},
  journal={nature},
  volume={550},
  number={7676},
  pages={354--359},
  year={2017},
  publisher={Nature Publishing Group UK London}
}
@article{recht2019tour,
  title={A tour of reinforcement learning: The view from continuous control},
  author={Recht, Benjamin},
  journal={Annual Review of Control, Robotics, and Autonomous Systems},
  volume={2},
  number={1},
  pages={253--279},
  year={2019},
  publisher={Annual Reviews}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}
@inproceedings{haarnoja2018soft,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={1861--1870},
  year={2018},
  organization={Pmlr}
}

@inproceedings{fujimoto2018addressing,
  title={Addressing function approximation error in actor-critic methods},
  author={Fujimoto, Scott and Hoof, Herke and Meger, David},
  booktitle={International conference on machine learning},
  pages={1587--1596},
  year={2018},
  organization={PMLR}
}
@inproceedings{jia2023robust,
  title={Robust Attitude Controller Designation of Launch Vehicle under Actuator Failure Condition via Deep Reinforcement Learning Algorithm},
  author={Jia, Chenhui and Liu, Xiaodong and Wang, Zhaolei and Gong, Qinghai and Huang, Xu},
  booktitle={2023 35th Chinese Control and Decision Conference (CCDC)},
  pages={3223--3228},
  year={2023},
  organization={IEEE}
}
@inproceedings{todorov2012mujoco,
  title={Mujoco: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={2012 IEEE/RSJ international conference on intelligent robots and systems},
  pages={5026--5033},
  year={2012},
  organization={IEEE}
}

@article{makoviychuk2021isaac,
  title={Isaac gym: High performance gpu-based physics simulation for robot learning},
  author={Makoviychuk, Viktor and Wawrzyniak, Lukasz and Guo, Yunrong and Lu, Michelle and Storey, Kier and Macklin, Miles and Hoeller, David and Rudin, Nikita and Allshire, Arthur and Handa, Ankur and others},
  journal={arXiv preprint arXiv:2108.10470},
  year={2021}
}

@inproceedings{peng2018sim,
  title={Sim-to-real transfer of robotic control with dynamics randomization},
  author={Peng, Xue Bin and Andrychowicz, Marcin and Zaremba, Wojciech and Abbeel, Pieter},
  booktitle={2018 IEEE international conference on robotics and automation (ICRA)},
  pages={3803--3810},
  year={2018},
  organization={IEEE}
}

@inproceedings{zhao2020sim,
  title={Sim-to-real transfer in deep reinforcement learning for robotics: a survey},
  author={Zhao, Wenshuai and Queralta, Jorge Pe{\~n}a and Westerlund, Tomi},
  booktitle={2020 IEEE symposium series on computational intelligence (SSCI)},
  pages={737--744},
  year={2020},
  organization={IEEE}
}
@article{glossop2022characterising,
  title={Characterising the robustness of reinforcement learning for continuous control using disturbance injection},
  author={Glossop, Catherine R and Panerati, Jacopo and Krishnan, Amrit and Yuan, Zhaocong and Schoellig, Angela P},
  journal={arXiv preprint arXiv:2210.15199},
  year={2022}
}

@article{kober2013survey,
  title={Reinforcement learning in robotics: A survey},
  author={Kober, Jens and Bagnell, J Andrew and Peters, Jan},
  journal={The International Journal of Robotics Research},
  volume={32},
  number={11},
  pages={1238--1274},
  year={2013},
  publisher={SAGE Publications Sage UK: London, England}
}

@book{zhou1998essentials,
  title={Essentials of robust control},
  author={Zhou, Kemin and Doyle, John Comstock},
  volume={104},
  year={1998},
  publisher={Prentice hall Upper Saddle River, NJ}
}

@article{zhang2008bibliographical,
  title={Bibliographical review on reconfigurable fault-tolerant control systems},
  author={Zhang, Youmin and Jiang, Jin},
  journal={Annual reviews in control},
  volume={32},
  number={2},
  pages={229--252},
  year={2008},
  publisher={Elsevier}
}

@inproceedings{tobin2017domain,
  title={Domain randomization for transferring deep neural networks from simulation to the real world},
  author={Tobin, Josh and Fong, Rachel and Ray, Alex and Schneider, Jonas and Zaremba, Wojciech and Abbeel, Pieter},
  booktitle={2017 IEEE/RSJ international conference on intelligent robots and systems (IROS)},
  pages={23--30},
  year={2017},
  organization={IEEE}
}
@article{mouret2015illuminating,
  title={Illuminating search spaces by mapping elites},
  author={Mouret, Jean-Baptiste and Clune, Jeff},
  journal={arXiv preprint arXiv:1504.04909},
  year={2015}
}

@article{allard2023online,
  title={Online damage recovery for physical robots with hierarchical quality-diversity},
  author={Allard, Maxime and Smith, Sim{\'o}n C and Chatzilygeroudis, Konstantinos and Lim, Bryan and Cully, Antoine},
  journal={ACM Transactions on Evolutionary Learning},
  volume={3},
  number={2},
  pages={1--23},
  year={2023},
  publisher={ACM New York, NY}
}

@inproceedings{schulman2015trust,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={International conference on machine learning},
  pages={1889--1897},
  year={2015},
  organization={PMLR}
}

@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}
@article{pugh2016quality,
  title={Quality diversity: A new frontier for evolutionary computation},
  author={Pugh, Justin K and Soros, Lisa B and Stanley, Kenneth O},
  journal={Frontiers in Robotics and AI},
  volume={3},
  pages={40},
  year={2016},
  publisher={Frontiers Media SA}
}
@inproceedings{coulom2006efficient,
  title={Efficient selectivity and backup operators in Monte-Carlo tree search},
  author={Coulom, R{\'e}mi},
  booktitle={International conference on computers and games},
  pages={72--83},
  year={2006},
  organization={Springer}
}
@inproceedings{kocsis2006bandit,
  title={Bandit based monte-carlo planning},
  author={Kocsis, Levente and Szepesv{\'a}ri, Csaba},
  booktitle={European conference on machine learning},
  pages={282--293},
  year={2006},
  organization={Springer}
}

@incollection{littman1995,
  title={Learning policies for partially observable environments: Scaling up},
  author={Littman, Michael L and Cassandra, Anthony R and Kaelbling, Leslie Pack},
  booktitle={Machine Learning Proceedings 1995},
  pages={362--370},
  year={1995},
  publisher={Elsevier}
}
@article{monahan1982state,
  title={State of the artâ€”a survey of partially observable Markov decision processes: theory, models, and algorithms},
  author={Monahan, George E},
  journal={Management science},
  volume={28},
  number={1},
  pages={1--16},
  year={1982},
  publisher={INFORMS}
}